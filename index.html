<!DOCTYPE html>

<html lang="en" class="dark">
  <head>
    <meta charset="UTF-8">

    <meta name="description" content="Project website for RoboFuME">
    <meta name="author" content="Jingyun Yang">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="icon" href="icons/robot_icon.png">
    <script src="https://cdn.tailwindcss.com"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/flowbite/1.8.1/flowbite.min.js"></script>
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.4/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/js/bootstrap.min.js"></script>
    <script src="https://unpkg.com/@babel/standalone/babel.min.js"></script>
    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-8G9PY3DPRC"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-8G9PY3DPRC');
    </script>
    <!-- Code formatting -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/default.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <title>RoboFuME</title>
  </head>

  <style>
    .grad_text {
      background: -webkit-linear-gradient(right, rgba(44,83,131,1), rgba(95,175,201,1));
      -webkit-background-clip: text;
      -webkit-text-fill-color: transparent;
    }
  </style>

  <body>
    <section>
      <div class="relative items-center w-full px-5 pt-12 pb-2 mx-auto md:px-12 lg:px-16 max-w-7xl lg:pt-24 lg:pb-4">
        <div class="flex w-full mx-auto text-left">
          <div class="relative inline-flex items-center mx-auto align-middle">
            <div class="text-center">
              <h1 class="max-w-5xl text-3xl font-bold leading-none tracking-tighter text-black-600 md:text-5xl lg:text-5xl lg:max-w-7xl">
                <span class="grad_text">Robot Fine-Tuning Made Easy</span>: Pre-Training Rewards and Policies for Autonomous Real-World Reinforcement Learning
              </h1>
              <div class="space-y-2">
                <p class="max-w-6xl mx-auto mt-8 text-md md:text-xl lg:text-xl lg:text-xl leading-relaxed text-gray-600 space-x-5">
                  <a href="https://yjy0625.github.io/" class="hover:text-gray-800">Jingyun Yang*</a>
                  <a href="https://profiles.stanford.edu/joel-sobol-mark/" class="hover:text-gray-800">Max Sobol Mark*</a>
                  <a href="https://profiles.stanford.edu/240111/" class="hover:text-gray-800">Brandon Vu</a>
                  <a href="https://architsharma97.github.io/" class="hover:text-gray-800">Archit Sharma</a>
                  <a href="https://web.stanford.edu/~bohg/" class="hover:text-gray-800">Jeannette Bohg</a>
                  <a href="https://ai.stanford.edu/~cbfinn/" class="hover:text-gray-800">Chelsea Finn</a>
                </p>
                <p class="max-w-6xl mx-auto mt-8 text-md md:text-xl lg:text-xl lg:text-xl leading-relaxed text-gray-400 space-x-7">
                  <span>*Equal Contribution</span>
                  <span>Stanford University</span>
                </p>
              </div>
              <div class="flex items-center justify-center w-full max-w-2xl gap-2 mx-auto mt-6">
                <a href="https://arxiv.org/abs/2310.15145" class="inline-flex items-center text-white bg-gray-700 hover:bg-gray-800 focus:ring-4 focus:ring-gray-300 font-medium rounded-lg text-sm px-4 py-3 mr-2 mb-2 dark:bg-gray-600 dark:hover:bg-gray-700 focus:outline-none dark:focus:ring-gray-800">
                  <svg aria-hidden="true" class="w-5 h-5 mr-2" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" class="w-6 h-6">
                    <path stroke-linecap="round" stroke-linejoin="round" d="M19.5 14.25v-2.625a3.375 3.375 0 00-3.375-3.375h-1.5A1.125 1.125 0 0113.5 7.125v-1.5a3.375 3.375 0 00-3.375-3.375H8.25m2.25 0H5.625c-.621 0-1.125.504-1.125 1.125v17.25c0 .621.504 1.125 1.125 1.125h12.75c.621 0 1.125-.504 1.125-1.125V11.25a9 9 0 00-9-9z" />
                  </svg>
                  <span>Paper</span>
                </a>
                <a href="https://youtu.be/BnFPav1viBA" class="inline-flex items-center text-white bg-gray-700 hover:bg-gray-800 focus:ring-4 focus:ring-gray-300 font-medium rounded-lg text-sm px-4 py-3 mr-2 mb-2 dark:bg-gray-600 dark:hover:bg-gray-700 focus:outline-none dark:focus:ring-gray-800">
                  <svg aria-hidden="true" class="w-5 h-5 mr-2" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" class="w-6 h-6">
                    <path stroke-linecap="round" stroke-linejoin="round" d="M21 12a9 9 0 11-18 0 9 9 0 0118 0z" /><path stroke-linecap="round" stroke-linejoin="round" d="M15.91 11.672a.375.375 0 010 .656l-5.603 3.113a.375.375 0 01-.557-.328V8.887c0-.286.307-.466.557-.327l5.603 3.112z" />
                  </svg>
                  <span>Video</span>
                </a>
                <a href="#" class="inline-flex items-center text-white bg-gray-700 hover:bg-gray-800 focus:ring-4 focus:ring-gray-300 font-medium rounded-lg text-sm px-4 py-3 mr-2 mb-2 dark:bg-gray-600 dark:hover:bg-gray-700 focus:outline-none dark:focus:ring-gray-800">
                  <svg aria-hidden="true" class="w-5 h-5 mr-2" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" class="w-6 h-6">
                    <path stroke-linecap="round" stroke-linejoin="round" d="M14.25 9.75L16.5 12l-2.25 2.25m-4.5 0L7.5 12l2.25-2.25M6 20.25h12A2.25 2.25 0 0020.25 18V6A2.25 2.25 0 0018 3.75H6A2.25 2.25 0 003.75 6v12A2.25 2.25 0 006 20.25z" />
                  </svg>
                  <span>Code (Coming Soon)</span>
                </a>
              </div>
            </div>
          </div>
        </div>
        <div class="flex flex-col items-center justify-center pt-6 mx-auto rounded-lg lg:px-10 max-w-7xl">
          <div>
            <video class="w-full h-auto" autoplay loop muted>
              <source src="./videos/teaser.mp4" type="video/mp4">
            </video>
          </div>
        </div>
      </div>
      <div class="flex flex-col items-center px-5 pt-8 pb-6 my-6 mx-auto max-w-5xl sm:px-6 lg:px-8">
        <div class="flex flex-col w-full max-w-5xl mx-auto border-l-4 p-12 rounded-r-xl bg-gray-50 prose text-left text-gray-800 leading-7">
          <h2 class="text-2xl font-bold pb-5"><span>Abstract</span></h2>
          <p>
            The pre-train and fine-tune paradigm in machine learning has had dramatic success in a wide range of domains because the use of existing data or pre-trained models on the Internet enables quick and easy learning of new tasks. We aim to enable this paradigm in robotic reinforcement learning, allowing a robot to learn a new task with little human effort by leveraging data and models from the Internet. However, reinforcement learning often requires significant human effort in the form of manual reward specification or environment resets, even if the policy is pre-trained. We introduce RoboFuME, a reset-free fine-tuning system that pre-trains a multi-task manipulation policy from diverse datasets of prior experiences and self-improves online to learn a target task with minimal human intervention. Our insights are to utilize calibrated offline reinforcement learning techniques to ensure efficient online fine-tuning of a pre-trained policy in the presence of distribution shifts and leverage pre-trained vision language models (VLMs) to build a robust reward classifier for autonomously providing reward signals during the online fine-tuning process. In a diverse set of five real robot manipulation tasks, we show that our method can incorporate data from an existing robot dataset collected at a different institution and improve on a target task within as little as 3 hours of autonomous real-world experience. We also demonstrate in simulation experiments that our method outperforms prior works that use different RL algorithms or different approaches for predicting rewards.
          </p>
        </div>
      </div>
      <div class="flex flex-col items-center px-5 pt-6 pb-3 mx-auto max-w-6xl sm:px-6 lg:px-8">
        <div class="flex flex-col w-full max-w-6xl mx-auto prose text-left text-gray-800">
          <h2 class="text-2xl font-bold pb-5"><span class="grad_text">Video</span></h2>
          <div>
            <video class="w-full h-auto border-4 border-gray-200 rounded-2xl" controls="">
              <source src="./videos/robofume.mp4" type="video/mp4">
            </video>
          </div>
        </div>
      </div>
      <div class="flex flex-col items-center px-5 pt-9 pb-3 mx-auto max-w-6xl sm:px-6 lg:px-8">
        <div class="flex flex-col w-full max-w-6xl mx-auto prose text-left text-gray-800">
          <h2 class="text-2xl font-bold pb-5"><span class="grad_text">Motivation</span></h2>
          <div>
            <p>
              The pre-train and fine-tune paradigm in machine learning has had dramatic success in a wide range of domains because the use of existing data and pre-trained models enables quick and easy learning of new tasks. The goal of this paper is to enable this paradigm in robot reinforcement learning.
            </p>
            <div class="flex flex-col items-center justify-center py-6 mx-auto lg:px-1 max-w-4xl">
              <img src="images/motivation.png" class="object-cover object-center">
            </div>
          </div>
        </div>
      </div>
      <div class="flex flex-col items-center px-5 pt-9 pb-3 mx-auto max-w-6xl sm:px-6 lg:px-8">
        <div class="flex flex-col w-full max-w-6xl mx-auto prose text-left text-gray-800">
          <h2 class="text-2xl font-bold pb-5"><span class="grad_text">Method Overview</span></h2>
          <div>
            <p>
              We propose a system that enables autonomous and efficient real-world robot learning by first pre-training a VLM reward model and a multi-task policy from diverse off-the-shelf demonstration datasets and then fine-tuning the pre-trained policy online with the VLM reward model.
            </p>
            <div class="flex flex-col items-center justify-center py-6 mx-auto lg:px-1 max-w-5xl">
              <img src="images/teaser.png" class="object-cover object-center">
            </div>
          </div>
        </div>
      </div>
      <div class="flex flex-col items-center px-5 pt-9 pb-3 mx-auto max-w-6xl sm:px-6 lg:px-8">
        <div class="flex flex-col w-full max-w-6xl mx-auto prose text-left text-gray-800">
          <h2 class="text-2xl font-bold pb-5"><span class="grad_text">Real Robot Experiments</span></h2>
          <div>
            <p class="font-bold pb-2">Tasks</p>
            <p>
              We test our system on five different manipulation tasks: candy sweeping, cloth folding, object covering, pot lid, and pot pick-and-place.
            </p>
            <div class="relative items-center w-full px-0 pt-6 pb-6 mx-auto max-w-6xl">
              <div class="grid w-9/12 grid-cols-1 gap-3 mx-auto md:grid-cols-5 md:w-full">
                <div class="flex flex-col items-center justify-center py-0 mx-auto max-w-5xl">
                  <video  class="w-full h-auto border border-gray-900 rounded-lg" autoplay loop muted>
                    <source src="./videos/tasks/candy_sweeping.mp4" type="video/mp4">
                  </video>
                  <p class="pt-2 text-gray-600">Candy Sweeping</p>
                </div>
                <div class="flex flex-col items-center justify-center py-0 mx-auto max-w-5xl">
                  <video class="w-full h-auto border border-gray-900 rounded-lg" autoplay loop muted>
                    <source src="./videos/tasks/cloth_folding.mp4" type="video/mp4">
                  </video>
                  <p class="pt-2 text-gray-600">Cloth Folding</p>
                </div>
                <div class="flex flex-col items-center justify-center py-0 mx-auto max-w-5xl">
                  <video class="w-full h-auto border border-gray-900 rounded-lg" autoplay loop muted>
                    <source src="./videos/tasks/object_covering.mp4" type="video/mp4">
                  </video>
                  <p class="pt-2 text-gray-600">Object Covering</p>
                </div>
                <div class="flex flex-col items-center justify-center py-0 mx-auto max-w-5xl">
                  <video class="w-full h-auto border border-gray-900 rounded-lg" autoplay loop muted>
                    <source src="./videos/tasks/pot_lid.mp4" type="video/mp4">
                  </video>
                  <p class="pt-2 text-gray-600">Pot Lid</p>
                </div>
                <div class="flex flex-col items-center justify-center py-0 mx-auto max-w-5xl">
                  <video class="w-full h-auto border border-gray-900 rounded-lg" autoplay loop muted>
                    <source src="./videos/tasks/pot_pnp.mp4" type="video/mp4">
                  </video>
                  <p class="pt-2 text-gray-600">Pot PNP</p>
                </div>
              </div>
            </div>
            <p class="font-bold pb-2">Prior Data</p>
            <p>
              We use diverse prior demonstration data from the <a href="https://rail-berkeley.github.io/bridgedata/" class="text-sky-600 hover:underline hover:text-sky-800">Bridge V2 dataset</a>, which was collected at a different institution. For each task, we pick about 1,000 relevant trajectories in the dataset as prior data for the agent.
            </p>
            <div class="flex flex-col items-center justify-center py-6 mx-auto max-w-6xl">
              <video height="auto" width="100%" autoplay loop muted>
                <source src="./videos/prior_data.mp4" type="video/mp4">
              </video>
            </div>
            <p class="font-bold pb-2">Target Task Demonstrations</p>
            <p>
              In addition to the prior data, we spend 30 minutes to collect 50 successful demos for both the forward and backward target tasks, as well as 10 minutes of failure demos for both tasks. Below, we show sample demos that we collected for the candy sweeping task.
            </p>
            <div class="relative items-center w-full px-0 pt-6 pb-6 mx-auto max-w-6xl">
              <div class="grid w-9/12 grid-cols-1 gap-2 pb-6 mx-auto md:grid-cols-2 md:w-full">
                <div class="flex flex-col items-center justify-center py-0 mx-auto max-w-5xl">
                  <video class="w-full h-auto border border-gray-900 rounded-lg" autoplay loop muted>
                    <source src="./videos/demos/candy_forward_pos.mp4" type="video/mp4">
                  </video>
                  <p class="pt-2 text-gray-600">Successful Forward Demos</p>
                </div>
                <div class="flex flex-col items-center justify-center py-0 mx-auto max-w-5xl">
                  <video class="w-full h-auto border border-gray-900 rounded-lg" autoplay loop muted>
                    <source src="./videos/demos/candy_backward_pos.mp4" type="video/mp4">
                  </video>
                  <p class="pt-2 text-gray-600">Successfull Backward Demos</p>
                </div>
              </div>
              <div class="grid w-9/12 grid-cols-1 gap-2 mx-auto md:grid-cols-2 md:w-full">
                <div class="flex flex-col items-center justify-center py-0 mx-auto max-w-5xl">
                  <video  class="w-full h-auto border border-gray-900 rounded-lg" autoplay loop muted>
                    <source src="./videos/demos/candy_forward_neg.mp4" type="video/mp4">
                  </video>
                  <p class="pt-2 text-gray-600">Failure Forward Demos</p>
                </div>
                <div class="flex flex-col items-center justify-center py-0 mx-auto max-w-5xl">
                  <video class="w-full h-auto border border-gray-900 rounded-lg" autoplay loop muted>
                    <source src="./videos/demos/candy_backward_neg.mp4" type="video/mp4">
                  </video>
                  <p class="pt-2 text-gray-600">Failure Backward Demos</p>
                </div>
              </div>
            </div>
            <p class="font-bold pb-2">Autonomous Fine-tuning</p>
            <p>
              We pre-train a reinforcement learning policy from both the prior data and the target demonstration data using an offline RL algorithm. Then, we rollout the policy to perform the forward and backward tasks alternatively while updating the policy with the VLM reward model as reward feedback. Since the policy is able to reset the environment after trying out the task, the fine-tuning phase can run with minimal human interventions. Below, we show timelapses of the fine-tuning stage for the candy sweeping and cloth covering tasks.
            </p>
            <div class="relative items-center w-full px-0 pt-6 pb-6 mx-auto max-w-6xl">
              <div class="grid w-9/12 grid-cols-1 gap-9 pb-6 mx-auto md:grid-cols-2 md:max-w-4xl">
                <div class="flex flex-col items-center justify-center py-0 mx-auto">
                  <video class="w-full h-auto border border-gray-900 rounded-lg" controls="" autoplay loop muted>
                    <source src="./videos/ft/candy.mp4" type="video/mp4">
                  </video>
                  <p class="pt-2 text-gray-600">Candy Sweeping</p>
                </div>
                <div class="flex flex-col items-center justify-center py-0 mx-auto">
                  <video class="w-full h-auto border border-gray-900 rounded-lg" controls="" autoplay loop muted>
                    <source src="./videos/ft/covering.mp4" type="video/mp4">
                  </video>
                  <p class="pt-2 text-gray-600">Cloth Covering</p>
                </div>
              </div>
            </div>
            <p class="font-bold pb-2">Quantitative Results</p>
            <p>
              Our method significantly improves over both offline-only and BC performance after 30k steps of online interaction (2-4 hours).
            </p>
            <div class="flex flex-col items-center justify-center py-6 mx-auto lg:px-1 max-w-4xl">
              <img src="images/real_robot_results.png" class="object-cover object-center">
            </div>
            <p class="font-bold pb-2">Evaluation Videos</p>
            <p class="pb-4">
              Below, we show evaluation videos for all 5 tasks. Please select tab to see evaluation videos for the corresponding task.
            </p>
            <div class="mb-4 border-b border-gray-200 dark:border-gray-700">
              <ul class="flex flex-wrap -mb-px text-sm font-medium text-center" id="eval_tabs" data-tabs-toggle="#eval_tab_contents">
                <li class="mr-2">
                  <button class="inline-block p-4 border-b-2 rounded-t-lg text-gray-900" id="candy-tab" data-tabs-target="#candy" type="button">Candy Sweeping</button>
                </li>
                <li class="mr-2">
                  <button class="inline-block p-4 border-b-2 border-transparent rounded-t-lg text-gray-400 hover:text-gray-600 hover:border-gray-300 dark:hover:text-gray-300" id="folding-tab" data-tabs-target="#folding" type="button">Cloth Folding</button>
                </li>
                <li class="mr-2">
                  <button class="inline-block p-4 border-b-2 border-transparent rounded-t-lg text-gray-400 hover:text-gray-600 hover:border-gray-300 dark:hover:text-gray-300" id="covering-tab" data-tabs-target="#covering" type="button">Object Covering</button>
                </li>
                <li class="mr-2">
                  <button class="inline-block p-4 border-b-2 border-transparent rounded-t-lg text-gray-400 hover:text-gray-600 hover:border-gray-300 dark:hover:text-gray-300" id="lid-tab" data-tabs-target="#lid" type="button">Pot Lid</button>
                </li>
                <li>
                  <button class="inline-block p-4 border-b-2 border-transparent rounded-t-lg text-gray-400 hover:text-gray-600 hover:border-gray-300 dark:hover:text-gray-300" id="pnp-tab" data-tabs-target="#pnp" type="button">Pot PNP</button>
                </li>
              </ul>
            </div>
            <div id="eval_tab_contents">
              <div class="p-6 rounded-lg bg-gray-50 dark:bg-gray-800" id="candy" aria-labelledby="candy-tab">
                <div class="grid w-9/12 grid-cols-1 gap-9 mx-auto md:grid-cols-3 md:w-full max-w-3xl">
                  <div class="flex flex-col items-center justify-center py-0 mx-auto max-w-5xl">
                    <video height="auto" width="auto" autoplay loop muted style="border: 1px solid #000;">
                      <source src="./videos/eval/candy_bc.mp4" type="video/mp4">
                    </video>
                    <p class="pt-2 text-gray-600">BC</p>
                  </div>
                  <div class="flex flex-col items-center justify-center py-0 mx-auto max-w-5xl">
                    <video height="auto" width="auto" autoplay loop muted style="border: 1px solid #000;">
                      <source src="./videos/eval/candy_offline.mp4" type="video/mp4">
                    </video>
                    <p class="pt-2 text-gray-600">Ours (Offline)</p>
                  </div>
                  <div class="flex flex-col items-center justify-center py-0 mx-auto max-w-5xl">
                    <video height="auto" width="auto" autoplay loop muted style="border: 1px solid #000;">
                      <source src="./videos/eval/candy_ft.mp4" type="video/mp4">
                    </video>
                    <p class="pt-2 text-gray-600">Ours (FT 3 Hours)</p>
                  </div>
                </div>
              </div>
              <div class="hidden p-6 rounded-lg bg-gray-50 dark:bg-gray-800" id="folding">
                <div class="grid w-9/12 grid-cols-1 gap-9 mx-auto md:grid-cols-3 md:w-full max-w-3xl">
                  <div class="flex flex-col items-center justify-center py-0 mx-auto max-w-5xl">
                    <video height="auto" width="auto" autoplay loop muted style="border: 1px solid #000;">
                      <source src="./videos/eval/fold_bc.mp4" type="video/mp4">
                    </video>
                    <p class="pt-2 text-gray-600">BC</p>
                  </div>
                  <div class="flex flex-col items-center justify-center py-0 mx-auto max-w-5xl">
                    <video height="auto" width="auto" autoplay loop muted style="border: 1px solid #000;">
                      <source src="./videos/eval/fold_offline.mp4" type="video/mp4">
                    </video>
                    <p class="pt-2 text-gray-600">Ours (Offline)</p>
                  </div>
                  <div class="flex flex-col items-center justify-center py-0 mx-auto max-w-5xl">
                    <video height="auto" width="auto" autoplay loop muted style="border: 1px solid #000;">
                      <source src="./videos/eval/fold_ft.mp4" type="video/mp4">
                    </video>
                    <p class="pt-2 text-gray-600">Ours (FT 3 Hours)</p>
                  </div>
                </div>
              </div>
              <div class="hidden p-6 rounded-lg bg-gray-50 dark:bg-gray-800" id="covering">
                <div class="grid w-9/12 grid-cols-1 gap-9 mx-auto md:grid-cols-3 md:w-full max-w-3xl">
                  <div class="flex flex-col items-center justify-center py-0 mx-auto max-w-5xl">
                    <video height="auto" width="auto" autoplay loop muted style="border: 1px solid #000;">
                      <source src="./videos/eval/cover_bc.mp4" type="video/mp4">
                    </video>
                    <p class="pt-2 text-gray-600">BC</p>
                  </div>
                  <div class="flex flex-col items-center justify-center py-0 mx-auto max-w-5xl">
                    <video height="auto" width="auto" autoplay loop muted style="border: 1px solid #000;">
                      <source src="./videos/eval/cover_offline.mp4" type="video/mp4">
                    </video>
                    <p class="pt-2 text-gray-600">Ours (Offline)</p>
                  </div>
                  <div class="flex flex-col items-center justify-center py-0 mx-auto max-w-5xl">
                    <video height="auto" width="auto" autoplay loop muted style="border: 1px solid #000;">
                      <source src="./videos/eval/cover_ft.mp4" type="video/mp4">
                    </video>
                    <p class="pt-2 text-gray-600">Ours (FT 3 Hours)</p>
                  </div>
                </div>
              </div>
              <div class="hidden p-6 rounded-lg bg-gray-50 dark:bg-gray-800" id="lid">
                <div class="grid w-9/12 grid-cols-1 gap-9 mx-auto md:grid-cols-3 md:w-full max-w-3xl">
                  <div class="flex flex-col items-center justify-center py-0 mx-auto max-w-5xl">
                    <video height="auto" width="auto" autoplay loop muted style="border: 1px solid #000;">
                      <source src="./videos/eval/pot_lid_bc.mp4" type="video/mp4">
                    </video>
                    <p class="pt-2 text-gray-600">BC</p>
                  </div>
                  <div class="flex flex-col items-center justify-center py-0 mx-auto max-w-5xl">
                    <video height="auto" width="auto" autoplay loop muted style="border: 1px solid #000;">
                      <source src="./videos/eval/pot_lid_offline.mp4" type="video/mp4">
                    </video>
                    <p class="pt-2 text-gray-600">Ours (Offline)</p>
                  </div>
                  <div class="flex flex-col items-center justify-center py-0 mx-auto max-w-5xl">
                    <video height="auto" width="auto" autoplay loop muted style="border: 1px solid #000;">
                      <source src="./videos/eval/pot_lid_ft.mp4" type="video/mp4">
                    </video>
                    <p class="pt-2 text-gray-600">Ours (FT 3 Hours)</p>
                  </div>
                </div>
              </div>
              <div class="hidden p-6 rounded-lg bg-gray-50 dark:bg-gray-800" id="pnp">
                <div class="grid w-9/12 grid-cols-1 gap-9 mx-auto md:grid-cols-3 md:w-full max-w-3xl">
                  <div class="flex flex-col items-center justify-center py-0 mx-auto max-w-5xl">
                    <video height="auto" width="auto" autoplay loop muted style="border: 1px solid #000;">
                      <source src="./videos/eval/pot_pnp_bc.mp4" type="video/mp4">
                    </video>
                    <p class="pt-2 text-gray-600">BC</p>
                  </div>
                  <div class="flex flex-col items-center justify-center py-0 mx-auto max-w-5xl">
                    <video height="auto" width="auto" autoplay loop muted style="border: 1px solid #000;">
                      <source src="./videos/eval/pot_pnp_offline.mp4" type="video/mp4">
                    </video>
                    <p class="pt-2 text-gray-600">Ours (Offline)</p>
                  </div>
                  <div class="flex flex-col items-center justify-center py-0 mx-auto max-w-5xl">
                    <video height="auto" width="auto" autoplay loop muted style="border: 1px solid #000;">
                      <source src="./videos/eval/pot_pnp_ft.mp4" type="video/mp4">
                    </video>
                    <p class="pt-2 text-gray-600">Ours (FT 3 Hours)</p>
                  </div>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
      <div class="flex flex-col items-center px-5 pt-9 pb-3 mx-auto max-w-6xl sm:px-6 lg:px-8">
        <div class="flex flex-col w-full max-w-6xl mx-auto prose text-left text-gray-800">
          <h2 class="text-2xl font-bold pb-5"><span class="grad_text">Simulation Experiments</span></h2>
          <div>
            <p>
              We use a suite of three simulated robotic manipulation environments to ablate contributions of different components of our algorithm.
            </p>
            <div class="grid w-9/12 grid-cols-1 gap-9 mx-auto md:grid-cols-3 md:w-full max-w-3xl">
              <div class="flex flex-col items-center justify-center py-6 mx-auto max-w-5xl">
                <video height="auto" width="100%" autoplay loop muted style="border: 1px solid #000;">
                  <source src="./videos/sim/weight.mp4" type="video/mp4">
                </video>
                <p class="pt-2 text-gray-600 text-center">Put <span class="text-sky-600">metal weight</span> from <br/> table to bin</p>
              </div>
              <div class="flex flex-col items-center justify-center py-6 mx-auto max-w-5xl">
                <video height="auto" width="100%" autoplay loop muted style="border: 1px solid #000;">
                  <source src="./videos/sim/bench.mp4" type="video/mp4">
                </video>
                <p class="pt-2 text-gray-600 text-center">Put <span class="text-sky-600">wood bench</span> from <br/> table to bin</p>
              </div>
              <div class="flex flex-col items-center justify-center py-6 mx-auto max-w-5xl">
                <video height="auto" width="100%" autoplay loop muted style="border: 1px solid #000;">
                  <source src="./videos/sim/vase.mp4" type="video/mp4">
                </video>
                <p class="pt-2 text-gray-600 text-center">Put <span class="text-sky-600">yellow vase</span> from <br/> table to bin</p>
              </div>
            </div>
            <p>
              We report the success rate over the course of training, averaged over three seeds. Our method RoboFuME outperforms BC, ARIEL+VLM, and MEDAL++ consistently on all three domains.
            </p>
            <div class="flex flex-col items-center justify-center pt-3 pb-6 mx-auto lg:px-1 max-w-5xl">
              <img src="images/sim_results.png" class="object-cover object-center">
            </div>
          </div>
        </div>
      </div>
      <div class="flex flex-col items-center px-5 pt-0 pb-12 mx-auto max-w-6xl sm:px-6 lg:px-8">
        <div class="flex flex-col w-full max-w-6xl mx-auto prose text-left text-gray-800">
          <h2 class="text-2xl font-bold pb-5"><span class="grad_text">BibTeX</span></h2>
          <pre><code class="language-plaintext text-sm sm:text-base inline-flex text-left items-center space-x-4 bg-gray-800 text-white rounded-lg p-4 pl-6">@misc{
  yang2023robot,
  title={Robot Fine-Tuning Made Easy: Pre-Training Rewards and Policies for Autonomous Real-World Reinforcement Learning},
  author={Jingyun Yang and Max Sobol Mark and Brandon Vu and Archit Sharma and Jeannette Bohg and Chelsea Finn},
  year={2023},
  eprint={2310.15145},
  archivePrefix={arXiv},
  primaryClass={cs.RO}
}</code></pre>
        </div>
      </div>
    </section>
    <footer class="bg-white mt-4" aria-labelledby="footer-heading">
      <h2 id="footer-heading" class="sr-only">Footer</h2>
      <div class="px-4 py-8 mx-auto bg-gray-50 w-full sm:px-6 lg:px-16">
        <div class="flex flex-wrap items-baseline lg:justify-center">
          <span class="text-sm text-center font-light text-gray-600">
            If you have any questions, please contact Jingyun Yang and Max Sobol Mark ({jingyuny, maxsobolmark} "at" stanford "dot" edu).
            <br/>
            Toyota Research Institute provided funds to support this work.
          </span>
        </div>
      </div>
    </footer>
    <script src="./scripts/scripts.js"></script>
  </body>
</html>